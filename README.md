# 2101_Dacon

- 2021년 1월 운동 동작 분류
  - 3축 가속도계(accelerometer)와 3축 자이로스코프(gyroscope)를 활용해 측정된 센서 데이터에 머신러닝 알고리즘을 적용해 운동 동작 인식 알고리즘 개발
  - 심사 기준: LogLoss
  - 1차 평가(Public Score): 테스트 데이터 중 랜덤 샘플 된 50%로 채점, 대회 기간 중 공개
  - 2차 평가(Private Score): 나머지 50 % 테스트 데이터로 채점, 대회 종료 직후 공개
- 결과 
  - 전체 461명중 26등

# EDA ISSUE

- 데이터는 그 측정 간격이 매우 좁아서 진동이 심했다.
  - 이런 자잘한 진동은 크게 도움이 되지 않을것이라 판단해 3이동평균으로 Smoothing 한 데이터와 30이동평균한 데이터와 같이 EDA 진행
- 측정기가 오른속 전완근에 붙여져 있다는 점에서 격렬한 운동시에 부착된 기계가 돌아가면서(땀으로 인해) x,y,z 축을 제대로 측정하지 못했다.
  - 이는 동일한 운동에 대해 x,y,z 축이 다른 acc 값으로 측정되어있다는 점에서 알 수 있었다.
  - 그리고 플랭크, pushup, 등의 운동을 고려할 때에 x축의 측정 방향이 손목쪽이라는것을 캐치하였다.
  - 손목쪽으로 측정되는 값은 격렬한 운동에도 크게 변하지 않으므로 매우 중요할것이라 생각하고 이를 중심으로 EDA 진행
- 사용자에 따라 그 측정의 acc,gy 가 각기 달랐다.
  - 이는 같은 운동임에도 사용자별로 가동범위가 달라서 gy 가 달라지고 힘이 달라서 acc가 달라지기 때문이였다.
  - acc 의 경우는 percentile(0.75) 값으로 Normalizing 한다던가 조치가 가능하였으나 gy 의 경우 '가동 범위' 였기 떄문에 생각보다는 큰 차이가 없을거라 판단하고 그대로 진행
- 데이터가 심하게 Imbalance 되어있다.
  - Non exercise 는 1500개 남짓인데 반해, 제일 적은 label 의 경우 14개밖에 되지 않았다.
  - weight 를 다르게 한다던가, Upsampling 을 진행해서 막아보려 했다. (다만 선택된 모델에 대해서는 그 효과가 없었다.)
- sample size 에 비해 운동종류가 너무 많다.(61가지)
  - 데이콘에서 제공하는 링크에 들어가보니, 그곳에서는 95%의 정확성을 달성했다고 나왔다.
  - 하지만 이는 '매우 많은' 데이터를 통해 얻은 정확성일 것이다. 그 경우에도 간신히 95%를 달성한것.
  - 내가 눈으로 봐도 절대 구분하지 못할 운동의 종류가 있었다.
  - 위를 종합했을때에 모델 정확성의 상한선은 85%정도라고 판단하였음
  - Public score 에 매몰되어 오히려 그 score 에 과적합되어서 private score 에서 낮은 순위를 얻는 과오를 범하지 않기 위해 public 값은 10% 안에만 드는것으로 하고 최대한 ROBUST 하게 진행
- acc 의 경우 '중력값' 이 더해져있기 때문에 정확한 측정이 어려움
  - 중력값은 1로 추정된다.
  - 중력값이 각 방향으로 분산되어 더해져있기 떄문에 이 역시 오차의 원인이 되었다.

# Modeling

**시행해 본 모델**

- LSTM : Dropout 0.2 를 적용한 단층 LSTM
  - Validation 이 0.9부근에서 좋아지지 않음
- Multi layer LSTM : 2~3 층 Dropout 0.2 를 적용
  - 0.8~0.9 수준 어느정도는 개선된 모습
- Bidirectional LSTM : 1~2층 Dropout 0.2 적용
  - 0.8 수준
  - validation loss 가 매우 빠르게 줄어 10epoch 내로 0.9~0.8 까지 떨어짐
- GRU : 위와 같이 Bidirectional,Multi 모두 적용해 보앗음
  - 0.7후반 ~ 0.9 수준
  - LSTM 보다 적합속도가 빠르고 성능이 약간 더 좋았음
- Multi route LSTM(GRU)
  - 데이터에서 ID 별로 최소, 최대값, 평균, Noise 등 뽑아낼 수 있는 좋은 정보들을 뽑아내었을 때에, 이 정보를 마냥 LSTM 에 넣을 수 없다는 생각에서 출발
  - 뽑은 정보들은 다른 길을 통해서 LSTM 의 출력값(32~64개의 OUTPUT)과 다이렉트로 합쳐지게 만듦
  - 즉 시계열 정보는 LSTM(GRU) 를 지나가면서 고려가 되고, 유용한 정보는 추가적으로 따로 만든 길을 통해 LSTM 을 거치지 않고 바로 이용할 수 있도록 만듦
  - LSTM 의 출력값과 우리가 직접 구한 요약치가 합쳐지고 난 이후에는 NN 모델로 1~2 층의 relu 를 쌓음
  - 노력에 비해 Validation 값은 0.9~1.1 수준
- LSTM(GRU)model + Upsampling(np.roll)
  - 주어진 데이터가 12초간의 짧은 '주기를' 가진 데이터 임을 이용
  - 즉 랜덤으로 데이터의 끝 부분을 잘라 앞에 붙이는 방식으로 Upsampling 을 진행
  - 하지만 이 경우에도 과적합이 해결되지 않았음 (0.8~1.0)
- XGboost + Upsampling(imblearn의 ADASYN)
  - 회귀의 경우 Upsampling 을 하였을 때에가 늘 성능이 더 좋았다.
  - 각 가지마다 분기되는 최소 sample 수를 제한할 떄 성능이 매우 좋았음
  - 적합을 여러번 해 본 결과, 원래 수준에서는 100개 남짓으로 제한하는것이 성능이 좋았다.
  - 0.7 ~ 0.8
- lgbm + Upsampling(imblearn의 ADASYN)
  - 위 xgboost 와 같음.
  - 0.7 ~ 0.6 후반
- DNN 모델(relu..)
  - 위처럼 lstm,gru 처럼 시간의 흐름을 고려하는 모델이 아니라 그냥 다층의 DNN 을 사용
  - lgbm,xgboost 도 적합속도가 느리고 LSTM 등의 모델은 더욱 느린데에다 렘을 너무 먹어 코랩이 중단되기 일수였다.
  - 하지만 그냥 쌓은 DNN 모델은 적합속도가 빠르고 또한 성능이 준수하여 이 모델을 집중적으로 훈련하기 시작
  - 다만 Upsampling methods 가 모두 안좋게 나와서 과적합이 심히 우려된다.
  - 0.6 초중반

# Result
- 전체 461명중 26등 (7%)
